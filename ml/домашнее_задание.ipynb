{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kVIU0QJFBU-A"
   },
   "source": [
    "Для начала импортируем необходимые библиотеки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Biq3jX8TBPJd"
   },
   "outputs": [],
   "source": [
    "import numpy as np #для матричных вычислений\n",
    "import pandas as pd #для анализа и предобработки данных\n",
    "import matplotlib.pyplot as plt #для визуализации\n",
    "import seaborn as sns #для визуализации\n",
    "\n",
    "from sklearn import metrics #метрики\n",
    "from sklearn import model_selection #методы разделения и валидации\n",
    "from sklearn import ensemble #ансамбли\n",
    "\n",
    "plt.style.use('seaborn-v0_8') #стиль отрисовки seaborn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PJil2ChtBaB-"
   },
   "source": [
    "1. Прочитайте таблицу с данными ('data/online_shoppers_intention.csv') и выведите ее на экран, чтобы убедиться, что чтение прошло успешно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R-LzTVApBZ0N",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/online_shoppers_intention.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6C8aQuZkBkx4"
   },
   "source": [
    "2. Выведите размер таблицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tOih4yDSBowL"
   },
   "outputs": [],
   "source": [
    "print(f\"Строк {df.shape[0]}. Столбцов {df.shape[1]}\")\n",
    "assert df.shape[0] > 12000 and df.shape[1] == 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q9rZOkA9Bqcm"
   },
   "source": [
    "3. В нашей таблице содержится информация о более чем 12 тысячах сессий на сайте интернет-магазина. Каждая сессия описывается 18 признаками.\n",
    "Удостоверьтесь в отсутствии пропусков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NDl705itBwmz"
   },
   "outputs": [],
   "source": [
    "nulls = df.isnull().sum()\n",
    "print(nulls)\n",
    "for col, sum in nulls.items():\n",
    "    assert sum-=0, f\"Имеются пропуски в колонке {col}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LtKKChnRB8x1"
   },
   "source": [
    "4. Закодируйте категориальные признаки с помощью простого горячего кодирования, используя уже знакомую нам функцию get_dummies():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jvoWy_9GB2xe"
   },
   "outputs": [],
   "source": [
    "types = df.dtypes\n",
    "#Категориальные признаки\n",
    "cat_features = list(types[(types == 'object')].index)\n",
    "print(cat_features) # ['Month', 'VisitorType']\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(40, 20))\n",
    "#Строим столбчатую диаграмму для категории Месяц\n",
    "sns.barplot(data=df, x=cat_features[0], y='Revenue', ax=axes[0])\n",
    "#Строим столбчатую диаграмму для категории Тип посетителя\n",
    "sns.barplot(data=df, x=cat_features[1], y='Revenue', ax=axes[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#по столбчатым диаграммам видим что максимум приходится на конец года - Октябрь, Ноябрь, Декабь\n",
    "# в Январе и феврале - минимум продаж - этот признак отбрасывать нельзя\n",
    "\n",
    "#по типу клиента связь выражена не так сильно как по месяцам, но все-же есть. (тоже не отбрасываем)\n",
    "\n",
    "print(df.describe(include='object'))\n",
    "df_dummies = pd.get_dummies(df)\n",
    "print(f\"Описание после преобразования категориальных признаков. Количество колонок {df_dummies.dtypes.shape}\")\n",
    "print(df_dummies.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fhvLgkakCA1t"
   },
   "source": [
    "5. Теперь, когда необходимые преобразования выполнены, мы можем говорить о построении модели.\n",
    "\n",
    "Итак, нам необходимо предсказать целевую переменную Revenue — признак покупки. Целевой признак является бинарным категориальным, то есть мы решаем задачу бинарной классификации.\n",
    "В первую очередь визуализируйте соотношение классов в данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "woScUkcUCGM-"
   },
   "outputs": [],
   "source": [
    "sns.countplot(data=df, x='Revenue')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "corr = df_dummies.corr(method='spearman')\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
    "plt.show()\n",
    "\n",
    "# По heatmap видимо что признаки Administrative_Duration, Informational, Informational_Duration, ProductRelated, ProductRelated_Duration -\n",
    "# коррелируют между собой плюс минус одинаково, что приведет нас к мультиколлинеарности при использовании линейной или пол. регрессии\n",
    "# Будем использовать Случайный лес\n",
    "# Суть этого метода заключается в том, что каждая модель обучается не на всех признаках, а только на части из них.\n",
    "# Такой подход позволяет уменьшить коррелированность между ответами деревьев и сделать их независимыми друг от друга.\n",
    "\n",
    "# Также видно что некоторые аттрибуты слабо коррелируют по отношению к целевому признаку\n",
    "# Удаляем те, что ниже 0.02\n",
    "df_dummies = df_dummies.drop(['OperatingSystems', 'Browser', 'TrafficType', 'Month_Aug', 'Month_Jul', 'VisitorType_Other'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CKrXu50UCN4n"
   },
   "source": [
    "6. Сбалансирована ли данная выборка? Обоснуйте свою позицию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aNfPzVzRCUWL"
   },
   "outputs": [],
   "source": [
    "Выборка не сбалансирована. Купленных машин в несколько раз меньше по завершении сессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UTnuDsX2CZup"
   },
   "source": [
    "7. Из 12330 сессий покупкой товара завершаются лишь 15.47 %. Мы знаем, что такое соотношение классов заставляет нас смотреть на метрики для каждого из классов отдельно.\n",
    "\n",
    "Условимся, что лучшей будет считаться та модель, у которой значение метрики F1 для пользователей, совершивших покупку, будет наибольшим.\n",
    "\n",
    "Разделите набор данных на матрицу наблюдений X и вектор ответов y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KcCp1PoxCche"
   },
   "outputs": [],
   "source": [
    "X = df_dummies.drop('Revenue', axis=1)\n",
    "y = df_dummies['Revenue']\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, random_state=42, test_size=0.2, shuffle=True)\n",
    "\n",
    "december_train = X_train[X_train['Month_Dec'] == True].count()['Month_Dec']\n",
    "december_test = X_test[X_test['Month_Dec'] == True].count()['Month_Dec']\n",
    "#убеждаемся, что данные за декабрь попали как в тест, так и в трейн\n",
    "print(f\"Декабрьских сессий в трейне {december_train} и в тесте {december_test}\")\n",
    "#Декабрьских сессий в трейне 1387 и в тесте 340\n",
    "\n",
    "#Соотношение целевого признака в train и в test (должно быть примерно одинаковым)\n",
    "print('Train:\\n', y_train.value_counts(normalize=True), sep='')\n",
    "print('Valid:\\n', y_test.value_counts(normalize=True), sep='')\n",
    "#Revenue\n",
    "#False    0.848236\n",
    "#True     0.151764\n",
    "#Name: proportion, dtype: float64\n",
    "#Valid:\n",
    "#Revenue\n",
    "#False    0.833333\n",
    "#True     0.166667\n",
    "#Name: proportion, dtype: float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FrWLIMoFCgLl"
   },
   "source": [
    "Давайте заранее определимся, как мы будем производить контроль качества наших моделей:\n",
    "\n",
    "Разделим выборку на тренировочную и тестовую.\n",
    "Будем проводить кросс-валидацию на тренировочной выборке (то есть будем делить её на тренировочные и валидационные фолды и считать среднее значение метрики по фолдам).\n",
    "Итого мы будем использовать два показателя:\n",
    "\n",
    "значение метрики на тренировочных и валидационных фолдах кросс-валидации (по ним мы будем отслеживать переобучение модели и подбирать внешние параметры);\n",
    "значение метрики на отложенной тестовой выборке (оно будет нашим контрольным показателем).\n",
    "Другими словами, мы будем сочетать hold-оut- и k-fold-подходы к валидации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PpQvj38YCjXL"
   },
   "source": [
    "8. Для начала позаботимся о создании отложенной тестовой выборки.\n",
    "\n",
    "Разделите выборку на тренировочную и тестовую в соотношении 80/20. Используйте разбиение, стратифицированное по целевому признаку. В качестве значения параметра random_state возьмите число 42.\n",
    "\n",
    "Чему равно количество сессий на сайте в тренировочной выборке?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3_jcbvrHCk8L"
   },
   "outputs": [],
   "source": [
    "print(f\"всего данных трейн {y_train.count()} тест {y_test.count()}\")\n",
    "#всего данных трейн 9864 тест 2466"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M6gVxMTqCoPd"
   },
   "source": [
    "9. Расчитайте количество сессий в тестовой выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i69p0t11CqX3"
   },
   "outputs": [],
   "source": [
    "2466"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6dv38ggKCvgj"
   },
   "source": [
    "10.Коллеги посоветовали нам использовать случайный лес (Random Forest) для решения данной задачи. Давайте последуем их совету.\n",
    "\n",
    "Создайте модель случайного леса. В качестве значения параметра random_state возьмите число 42. Остальные параметры оставьте по умолчанию.\n",
    "\n",
    "Оцените качество такой модели с помощью кросс-валидации по пяти фолдам. Так как классы несбалансированы, используйте кросс-валидатор StratifiedKFold (перемешивать выборку не нужно).\n",
    "\n",
    "Для проведения кросс-валидации используйте функцию cross_validate(). Набор данных (параметры X, y) — тренировочная выборка (X_train, y_train). Метрика — F1-score.\n",
    "\n",
    "Расчитайте, чему равно среднее значение метрики  на тренировочных и валидационных фолдах?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vF1gs3PTDAC_"
   },
   "outputs": [],
   "source": [
    "#Производим нормализацию данных с помощью min-max нормализации\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#Создаем объект класса случайный лес\n",
    "rf = ensemble.RandomForestClassifier(\n",
    "    random_state=42\n",
    ")\n",
    "#Обучаем модель\n",
    "rf.fit(X_train, y_train)\n",
    "#Выводим значения метрики\n",
    "y_train_pred = rf.predict(X_train)\n",
    "print('Train: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
    "y_test_pred = rf.predict(X_test)\n",
    "print('Test: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "68JEDAaqDIGh"
   },
   "source": [
    "11. Является ли, по-вашему, построенная в предыдущем задании модель случайного леса переобученной? Обоснуйте вашу позицию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QOvDZw86DKRg"
   },
   "outputs": [],
   "source": [
    "Train: 1.00\n",
    "Test: 0.62\n",
    "Да, переобучено, так как на тренировочных данных идеальный результат, а на тестовых плохой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LtaA5tJZDKtt"
   },
   "source": [
    "12. Попробуем использовать несколько вариаций случайного леса и с помощью кривых обучения постараемся выбрать наилучшую из них.\n",
    "\n",
    "Создайте список из трёх следующих моделей:\n",
    "\n",
    "Случайный лес из деревьев максимальной глубины 5.\n",
    "Случайный лес из деревьев максимальной глубины 7.\n",
    "Случайный лес из деревьев максимальной глубины 12.\n",
    "Для всех трёх моделей количество деревьев в лесу (n_estimators) возьмите равным 200, количество объектов в листе (min_samples_leaf) — 5. Параметр random_state = 42. Остальные параметры оставьте по умолчанию.\n",
    "\n",
    "Постройте для каждой из моделей кривую обучения.\n",
    "Совет: воспользуйтесь функцией plot_learning_curve()\n",
    "\n",
    "Для построения кривых используйте обучающий набор данных (X_train, y_train), стратифицированный кросс-валидатор на пяти фолдах (StratifiedKFold) и метрику F1-score. Остальные параметры функции learning_curve() оставьте по умолчанию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZE5ro_DiDSMT"
   },
   "outputs": [],
   "source": [
    "def plot_learning_curve(model, X, y, ax=None, title=\"\"):\n",
    "    kf = model_selection.StratifiedKFold(n_splits=5)\n",
    "    train_sizes, train_scores, valid_scores = model_selection.learning_curve(\n",
    "        estimator=model,  # модель\n",
    "        X=X,  # матрица наблюдений X\n",
    "        y=y,  # вектор ответов y\n",
    "        cv=kf,  # кросс-валидатор\n",
    "        scoring='f1'  # метрика\n",
    "    )\n",
    "    # Вычисляем среднее значение по фолдам для каждого набора данных\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    valid_scores_mean = np.mean(valid_scores, axis=1)\n",
    "    # Строим кривую обучения по метрикам на тренировочных фолдах\n",
    "    ax.plot(train_sizes, train_scores_mean, label=\"Train\")\n",
    "    # Строим кривую обучения по метрикам на валидационных фолдах\n",
    "    ax.plot(train_sizes, valid_scores_mean, label=\"Valid\")\n",
    "    # Даём название графику и подписи осям\n",
    "    ax.set_title(\"Learning curve: {}\".format(title))\n",
    "    ax.set_xlabel(\"Train data size\")\n",
    "    ax.set_ylabel(\"Score\")\n",
    "    # Устанавливаем отметки по оси абсцисс\n",
    "    ax.xaxis.set_ticks(train_sizes)\n",
    "    # Устанавливаем диапазон оси ординат\n",
    "    ax.set_ylim(0, 1)\n",
    "    # Отображаем легенду\n",
    "    ax.legend()\n",
    "\n",
    "rf5 = ensemble.RandomForestClassifier(\n",
    "    criterion='entropy',\n",
    "    n_estimators=200,\n",
    "    max_depth=5,\n",
    "    min_samples_leaf=5,\n",
    "    random_state=42\n",
    ")\n",
    "rf7 = ensemble.RandomForestClassifier(\n",
    "    criterion='entropy',\n",
    "    n_estimators=200,\n",
    "    max_depth=7,\n",
    "    min_samples_leaf=5,\n",
    "    random_state=42\n",
    ")\n",
    "rf12 = ensemble.RandomForestClassifier(\n",
    "    criterion='entropy',\n",
    "    n_estimators=200,\n",
    "    max_depth=12,\n",
    "    min_samples_leaf=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4)) #фигура + 3 координатных плоскости\n",
    "plot_learning_curve(rf5, X_train_scaled, y_train, ax=axes[0], title='Глубина 5')\n",
    "plot_learning_curve(rf7, X_train_scaled, y_train, ax=axes[1], title='Глубина 7')\n",
    "plot_learning_curve(rf12, X_train_scaled, y_train, ax=axes[2], title='Глубина 12')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2NzTDouyDSjC"
   },
   "source": [
    "13. Из построенных кривых обучения сделайте вывод: какая глубина деревьев в лесу является оптимальной? Ответ обоснуйте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BzsLRZrKDeo6"
   },
   "outputs": [],
   "source": [
    "f1 метрика у модели с глубиной в 12 выше чем у модели 7 и 5. Если не обращать внимание на затраты на вычисление, нужно брать её."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O6BtRB--Dkrk"
   },
   "source": [
    "14. Обучите случайный лес с выбранной в предыдущем задании оптимальной глубиной на тренировочной выборке. Сделайте предсказание меток классов и выведите отчёт о метриках классификации.\n",
    "\n",
    " Рассчитайте значение метрики accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CbrhZIjVDnqW"
   },
   "outputs": [],
   "source": [
    "def random_forest_train(model, X, y, scoring):\n",
    "    # Создаём объект кросс-валидатора KFold\n",
    "    kf = model_selection.StratifiedKFold(n_splits=5)\n",
    "    # Считаем метрики на кросс-валидации k-fold\n",
    "    cv_metrics = model_selection.cross_validate(\n",
    "        estimator=model,  # модель\n",
    "        X=X,  # матрица наблюдений X\n",
    "        y=y,  # вектор ответов y\n",
    "        cv=kf,  # кросс-валидатор\n",
    "        scoring=scoring,  # метрика\n",
    "        return_train_score=True  # подсчёт метрики на тренировочных фолдах\n",
    "    )\n",
    "    #print(cv_metrics)\n",
    "    print('Train k-fold mean accuracy: {:.2f}'.format(np.mean(cv_metrics['train_score'])))\n",
    "    print('Valid k-fold mean accuracy: {:.2f}'.format(np.mean(cv_metrics['test_score'])))\n",
    "\n",
    "random_forest_train(rf12, X_train_scaled, y_train, 'accuracy')    \n",
    "#Train k-fold mean accuracy: 0.94\n",
    "#Valid k-fold mean accuracy: 0.91"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wX4YvysQDr9E"
   },
   "source": [
    "15. Рассчитайте значение метрики F1 для посетителей, завершивших сессию без покупки товара?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "569Z1bCVDvkG"
   },
   "outputs": [],
   "source": [
    "df_no_revenue = df_dummies.copy()\n",
    "df_no_revenue = df_no_revenue[df_no_revenue['Revenue'] == False]\n",
    "print(f\"Количество сессий без покупки {df_no_revenue.shape[0]}\")\n",
    "X_no_revenue = df_no_revenue.drop('Revenue', axis=1)\n",
    "y_no_revenue = df_no_revenue['Revenue']\n",
    "X_no_revenue_scaled = scaler.transform(X_no_revenue)\n",
    "y_no_revenue_pred = rf12.predict(X_no_revenue_scaled)\n",
    "print('F1 no revenue: {:.2f}'.format(metrics.f1_score(y_no_revenue, y_no_revenue_pred)))\n",
    "#Количество сессий без покупки 10422\n",
    "#F1 no revenue: 0.00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R0PMFYvEDz05"
   },
   "source": [
    "16. Рассчитайте значение метрики F1 для посетителей, купивших товар во время сессии?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PTDFBiTJD260"
   },
   "outputs": [],
   "source": [
    "df_revenue = df_dummies.copy()\n",
    "df_revenue = df_revenue[df_revenue['Revenue'] == True]\n",
    "print(f\"Количество сессий завершившихся покупкой {df_revenue.shape[0]}\")\n",
    "X_revenue = df_revenue.drop('Revenue', axis=1)\n",
    "y_revenue = df_revenue['Revenue']\n",
    "X_revenue_scaled = scaler.transform(X_revenue)\n",
    "y_revenue_pred = rf12.predict(X_revenue_scaled)\n",
    "print('F1 revenue: {:.2f}'.format(metrics.f1_score(y_revenue, y_revenue_pred)))\n",
    "#Количество сессий завершившихся покупкой 1908\n",
    "#F1 revenue: 0.78"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDn8OyohD_Hd"
   },
   "source": [
    "17. Напишите вывод по полученным значениям"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wmTUx8vrEFtQ"
   },
   "outputs": [],
   "source": [
    "Результат странный, по идее целевой признак бинарный и F1 должен был быть одинаков - т.е. если хорошо предсказываем один,\n",
    "то автоматически предсказыаем и другой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IxWQFvfkEGr2"
   },
   "source": [
    "18. Попробуем повысить качество распознавания посетителей, совершивших покупку. Используем метод подбора порога вероятности с помощью PR-кривой.\n",
    "\n",
    "Порог вероятности будем подбирать с помощью кросс-валидации.\n",
    "\n",
    "Сделайте предсказание вероятностей принадлежности к пользователям, которые совершат покупку, на кросс-валидации на пяти фолдах. Используйте метод cross_val_predict().\n",
    "\n",
    "Для кросс-валидации используйте случайный лес с подобранной в прошлых заданиях оптимальной максимальной глубиной деревьев, набор данных (параметры X, y) — тренировочная выборка (X_train, y_train).\n",
    "\n",
    "Постройте PR-кривую и отметьте на ней точку, в которой наблюдается максимум метрики  для посетителей, которые совершат покупку. Определите порог вероятности, соответствующий этой точке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vGUr7TeVENoc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9l8B5mh1EOW8"
   },
   "source": [
    "19. Сделайте предсказание классов объекта с определённым в предыдущем задании порогом вероятности. Выведите отчёт о метриках классификации.\n",
    "Рассчитайте значение метрики accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wKgFOzPxETRo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VvCxDjiJEdsR"
   },
   "source": [
    "20. Рассчитайте значение метрики F1 для посетителей, завершивших сессию без покупки товара и значение метрики F1 для посетителей, купивших товар во время сессии? После расчета напишите свои выводы на основе метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WQx6IxerEoa1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
